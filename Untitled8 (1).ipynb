{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HoUv-jd_wBX",
        "outputId": "87a1fdaf-774c-46ae-aec8-371413c428f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EDA for application_record:\n",
            "Dataset Shape: (438557, 18)\n",
            "Dataset Columns: Index(['ID', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN',\n",
            "       'AMT_INCOME_TOTAL', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
            "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'DAYS_BIRTH',\n",
            "       'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE',\n",
            "       'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS'],\n",
            "      dtype='object')\n",
            "\n",
            "Data Types and Non-Null Counts:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 438557 entries, 0 to 438556\n",
            "Data columns (total 18 columns):\n",
            " #   Column               Non-Null Count   Dtype  \n",
            "---  ------               --------------   -----  \n",
            " 0   ID                   438557 non-null  int64  \n",
            " 1   CODE_GENDER          438557 non-null  object \n",
            " 2   FLAG_OWN_CAR         438557 non-null  object \n",
            " 3   FLAG_OWN_REALTY      438557 non-null  object \n",
            " 4   CNT_CHILDREN         438557 non-null  int64  \n",
            " 5   AMT_INCOME_TOTAL     438557 non-null  float64\n",
            " 6   NAME_INCOME_TYPE     438557 non-null  object \n",
            " 7   NAME_EDUCATION_TYPE  438557 non-null  object \n",
            " 8   NAME_FAMILY_STATUS   438557 non-null  object \n",
            " 9   NAME_HOUSING_TYPE    438557 non-null  object \n",
            " 10  DAYS_BIRTH           438557 non-null  int64  \n",
            " 11  DAYS_EMPLOYED        438557 non-null  int64  \n",
            " 12  FLAG_MOBIL           438557 non-null  int64  \n",
            " 13  FLAG_WORK_PHONE      438557 non-null  int64  \n",
            " 14  FLAG_PHONE           438557 non-null  int64  \n",
            " 15  FLAG_EMAIL           438557 non-null  int64  \n",
            " 16  OCCUPATION_TYPE      304354 non-null  object \n",
            " 17  CNT_FAM_MEMBERS      438557 non-null  float64\n",
            "dtypes: float64(2), int64(8), object(8)\n",
            "memory usage: 60.2+ MB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "ID                          0\n",
            "CODE_GENDER                 0\n",
            "FLAG_OWN_CAR                0\n",
            "FLAG_OWN_REALTY             0\n",
            "CNT_CHILDREN                0\n",
            "AMT_INCOME_TOTAL            0\n",
            "NAME_INCOME_TYPE            0\n",
            "NAME_EDUCATION_TYPE         0\n",
            "NAME_FAMILY_STATUS          0\n",
            "NAME_HOUSING_TYPE           0\n",
            "DAYS_BIRTH                  0\n",
            "DAYS_EMPLOYED               0\n",
            "FLAG_MOBIL                  0\n",
            "FLAG_WORK_PHONE             0\n",
            "FLAG_PHONE                  0\n",
            "FLAG_EMAIL                  0\n",
            "OCCUPATION_TYPE        134203\n",
            "CNT_FAM_MEMBERS             0\n",
            "dtype: int64\n",
            "\n",
            "Summary Statistics:\n",
            "                 ID   CNT_CHILDREN  AMT_INCOME_TOTAL     DAYS_BIRTH  \\\n",
            "count  4.385570e+05  438557.000000      4.385570e+05  438557.000000   \n",
            "mean   6.022176e+06       0.427390      1.875243e+05  -15997.904649   \n",
            "std    5.716370e+05       0.724882      1.100869e+05    4185.030007   \n",
            "min    5.008804e+06       0.000000      2.610000e+04  -25201.000000   \n",
            "25%    5.609375e+06       0.000000      1.215000e+05  -19483.000000   \n",
            "50%    6.047745e+06       0.000000      1.607805e+05  -15630.000000   \n",
            "75%    6.456971e+06       1.000000      2.250000e+05  -12514.000000   \n",
            "max    7.999952e+06      19.000000      6.750000e+06   -7489.000000   \n",
            "\n",
            "       DAYS_EMPLOYED  FLAG_MOBIL  FLAG_WORK_PHONE     FLAG_PHONE  \\\n",
            "count  438557.000000    438557.0    438557.000000  438557.000000   \n",
            "mean    60563.675328         1.0         0.206133       0.287771   \n",
            "std    138767.799647         0.0         0.404527       0.452724   \n",
            "min    -17531.000000         1.0         0.000000       0.000000   \n",
            "25%     -3103.000000         1.0         0.000000       0.000000   \n",
            "50%     -1467.000000         1.0         0.000000       0.000000   \n",
            "75%      -371.000000         1.0         0.000000       1.000000   \n",
            "max    365243.000000         1.0         1.000000       1.000000   \n",
            "\n",
            "          FLAG_EMAIL  CNT_FAM_MEMBERS  \n",
            "count  438557.000000    438557.000000  \n",
            "mean        0.108207         2.194465  \n",
            "std         0.310642         0.897207  \n",
            "min         0.000000         1.000000  \n",
            "25%         0.000000         2.000000  \n",
            "50%         0.000000         2.000000  \n",
            "75%         0.000000         3.000000  \n",
            "max         1.000000        20.000000  \n",
            "\n",
            "Unique Counts for Each Column:\n",
            "ID                     438510\n",
            "CODE_GENDER                 2\n",
            "FLAG_OWN_CAR                2\n",
            "FLAG_OWN_REALTY             2\n",
            "CNT_CHILDREN               12\n",
            "AMT_INCOME_TOTAL          866\n",
            "NAME_INCOME_TYPE            5\n",
            "NAME_EDUCATION_TYPE         5\n",
            "NAME_FAMILY_STATUS          5\n",
            "NAME_HOUSING_TYPE           6\n",
            "DAYS_BIRTH              16379\n",
            "DAYS_EMPLOYED            9406\n",
            "FLAG_MOBIL                  1\n",
            "FLAG_WORK_PHONE             2\n",
            "FLAG_PHONE                  2\n",
            "FLAG_EMAIL                  2\n",
            "OCCUPATION_TYPE            18\n",
            "CNT_FAM_MEMBERS            13\n",
            "dtype: int64\n",
            "\n",
            "First 5 rows (df.head()):\n",
            "        ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
            "0  5008804           M            Y               Y             0   \n",
            "1  5008805           M            Y               Y             0   \n",
            "2  5008806           M            Y               Y             0   \n",
            "3  5008808           F            N               Y             0   \n",
            "4  5008809           F            N               Y             0   \n",
            "\n",
            "   AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
            "0          427500.0               Working               Higher education   \n",
            "1          427500.0               Working               Higher education   \n",
            "2          112500.0               Working  Secondary / secondary special   \n",
            "3          270000.0  Commercial associate  Secondary / secondary special   \n",
            "4          270000.0  Commercial associate  Secondary / secondary special   \n",
            "\n",
            "     NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "0        Civil marriage   Rented apartment      -12005          -4542   \n",
            "1        Civil marriage   Rented apartment      -12005          -4542   \n",
            "2               Married  House / apartment      -21474          -1134   \n",
            "3  Single / not married  House / apartment      -19110          -3051   \n",
            "4  Single / not married  House / apartment      -19110          -3051   \n",
            "\n",
            "   FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
            "0           1                1           0           0             NaN   \n",
            "1           1                1           0           0             NaN   \n",
            "2           1                0           0           0  Security staff   \n",
            "3           1                0           1           1     Sales staff   \n",
            "4           1                0           1           1     Sales staff   \n",
            "\n",
            "   CNT_FAM_MEMBERS  \n",
            "0              2.0  \n",
            "1              2.0  \n",
            "2              2.0  \n",
            "3              1.0  \n",
            "4              1.0  \n",
            "\n",
            "Last 5 rows (df.tail()):\n",
            "             ID CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
            "438552  6840104           M            N               Y             0   \n",
            "438553  6840222           F            N               N             0   \n",
            "438554  6841878           F            N               N             0   \n",
            "438555  6842765           F            N               Y             0   \n",
            "438556  6842885           F            N               Y             0   \n",
            "\n",
            "        AMT_INCOME_TOTAL      NAME_INCOME_TYPE            NAME_EDUCATION_TYPE  \\\n",
            "438552          135000.0             Pensioner  Secondary / secondary special   \n",
            "438553          103500.0               Working  Secondary / secondary special   \n",
            "438554           54000.0  Commercial associate               Higher education   \n",
            "438555           72000.0             Pensioner  Secondary / secondary special   \n",
            "438556          121500.0               Working  Secondary / secondary special   \n",
            "\n",
            "          NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  DAYS_BIRTH  DAYS_EMPLOYED  \\\n",
            "438552             Separated  House / apartment      -22717         365243   \n",
            "438553  Single / not married  House / apartment      -15939          -3007   \n",
            "438554  Single / not married       With parents       -8169           -372   \n",
            "438555               Married  House / apartment      -21673         365243   \n",
            "438556               Married  House / apartment      -18858          -1201   \n",
            "\n",
            "        FLAG_MOBIL  FLAG_WORK_PHONE  FLAG_PHONE  FLAG_EMAIL OCCUPATION_TYPE  \\\n",
            "438552           1                0           0           0             NaN   \n",
            "438553           1                0           0           0        Laborers   \n",
            "438554           1                1           0           0     Sales staff   \n",
            "438555           1                0           0           0             NaN   \n",
            "438556           1                0           1           0     Sales staff   \n",
            "\n",
            "        CNT_FAM_MEMBERS  \n",
            "438552              1.0  \n",
            "438553              1.0  \n",
            "438554              1.0  \n",
            "438555              2.0  \n",
            "438556              2.0  \n",
            "\n",
            "Unique values in 'OCCUPATION_TYPE':\n",
            "OCCUPATION_TYPE\n",
            "NaN                      134203\n",
            "Laborers                  78240\n",
            "Core staff                43007\n",
            "Sales staff               41098\n",
            "Managers                  35487\n",
            "Drivers                   26090\n",
            "High skill tech staff     17289\n",
            "Accountants               15985\n",
            "Medicine staff            13520\n",
            "Cooking staff              8076\n",
            "Security staff             7993\n",
            "Cleaning staff             5845\n",
            "Private service staff      3456\n",
            "Low-skill Laborers         2140\n",
            "Secretaries                2044\n",
            "Waiters/barmen staff       1665\n",
            "Realty agents              1041\n",
            "HR staff                    774\n",
            "IT staff                    604\n",
            "Name: count, dtype: int64\n",
            "\n",
            "EDA for credit_record:\n",
            "Dataset Shape: (1048575, 3)\n",
            "Dataset Columns: Index(['ID', 'MONTHS_BALANCE', 'STATUS'], dtype='object')\n",
            "\n",
            "Data Types and Non-Null Counts:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1048575 entries, 0 to 1048574\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count    Dtype \n",
            "---  ------          --------------    ----- \n",
            " 0   ID              1048575 non-null  int64 \n",
            " 1   MONTHS_BALANCE  1048575 non-null  int64 \n",
            " 2   STATUS          1048575 non-null  object\n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 24.0+ MB\n",
            "None\n",
            "\n",
            "Missing Values:\n",
            "ID                0\n",
            "MONTHS_BALANCE    0\n",
            "STATUS            0\n",
            "dtype: int64\n",
            "\n",
            "Summary Statistics:\n",
            "                 ID  MONTHS_BALANCE\n",
            "count  1.048575e+06    1.048575e+06\n",
            "mean   5.068286e+06   -1.913700e+01\n",
            "std    4.615058e+04    1.402350e+01\n",
            "min    5.001711e+06   -6.000000e+01\n",
            "25%    5.023644e+06   -2.900000e+01\n",
            "50%    5.062104e+06   -1.700000e+01\n",
            "75%    5.113856e+06   -7.000000e+00\n",
            "max    5.150487e+06    0.000000e+00\n",
            "\n",
            "Unique Counts for Each Column:\n",
            "ID                45985\n",
            "MONTHS_BALANCE       61\n",
            "STATUS                8\n",
            "dtype: int64\n",
            "\n",
            "First 5 rows (df.head()):\n",
            "        ID  MONTHS_BALANCE STATUS\n",
            "0  5001711               0      X\n",
            "1  5001711              -1      0\n",
            "2  5001711              -2      0\n",
            "3  5001711              -3      0\n",
            "4  5001712               0      C\n",
            "\n",
            "Last 5 rows (df.tail()):\n",
            "              ID  MONTHS_BALANCE STATUS\n",
            "1048570  5150487             -25      C\n",
            "1048571  5150487             -26      C\n",
            "1048572  5150487             -27      C\n",
            "1048573  5150487             -28      C\n",
            "1048574  5150487             -29      C\n",
            "----------------------------------------------------------------------------\n",
            "\n",
            "Number of classes: 8\n",
            "Actual classes: ['X' '0' 'C' '1' '2' '3' '4' '5']\n",
            "----------------------------------------------------------------------------\n",
            "\n",
            "Number of classes: 2\n",
            "Actual classes: [0 1]\n",
            "----------------------------------------------------------------------------\n",
            "\n",
            "Number of classes: 2\n",
            "Actual classes: [0 1]\n",
            "******************************************************************\n",
            "FINAL DF IS NAN 0\n",
            "FINAL DF IS NULL 0\n",
            "******************************************************************\n",
            "Initial number of duplicates: 0\n",
            "Initial number of missing values: 0\n",
            "After cleaning, number of duplicates: 0\n",
            "After cleaning, number of missing values: 0\n",
            "******************************************************************\n",
            "FINAL DF IS NAN 0\n",
            "FINAL DF IS NULL 0\n",
            "******************************************************************\n",
            "Found negative values in column 'DAYS_BIRTH'. Replacing with median.\n",
            "Found negative values in column 'DAYS_EMPLOYED'. Replacing with median.\n",
            "Found negative values in column 'MONTHS_BALANCE'. Replacing with median.\n",
            "After cleaning, number of records: 777715\n",
            "Cleaned dataset saved to 'mergedDataset.csv'\n",
            "***********************************************\n",
            " 0\n",
            "Number of classes: 2\n",
            "Actual classes: [0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py:635: UserWarning: Skipping features without any observed values: ['DAYS_BIRTH']. At least one non-missing value is needed for imputation with strategy='mean'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values after imputation: 0\n",
            "Index(['ID', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
            "       'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
            "       'CNT_FAM_MEMBERS', 'MONTHS_BALANCE', 'CODE_GENDER_Encoded',\n",
            "       'FLAG_OWN_CAR_Encoded', 'FLAG_OWN_REALTY_Encoded',\n",
            "       'NAME_INCOME_TYPE_Encoded', 'NAME_EDUCATION_TYPE_Encoded',\n",
            "       'NAME_FAMILY_STATUS_Encoded', 'NAME_HOUSING_TYPE_Encoded',\n",
            "       'OCCUPATION_TYPE_Encoded'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from deap import base, creator, tools, algorithms\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Step 1: Load datasets and perform EDA on 'application_record' and 'credit_record'\n",
        "def perform_eda(df, name):\n",
        "    print(f\"\\nEDA for {name}:\")\n",
        "    print(f\"Dataset Shape: {df.shape}\")\n",
        "    print(f\"Dataset Columns: {df.columns}\")\n",
        "\n",
        "    # Check data types and non-null counts\n",
        "    print(\"\\nData Types and Non-Null Counts:\")\n",
        "    print(df.info())\n",
        "\n",
        "    # Check for missing values\n",
        "    print(\"\\nMissing Values:\")\n",
        "    print(df.isnull().sum())\n",
        "\n",
        "    # Check basic statistics for numeric columns\n",
        "    print(\"\\nSummary Statistics:\")\n",
        "    print(df.describe())\n",
        "\n",
        "    # Check unique counts for each column\n",
        "    print(\"\\nUnique Counts for Each Column:\")\n",
        "    unique_counts = df.nunique()\n",
        "    print(unique_counts)\n",
        "\n",
        "    # Display the first few rows\n",
        "    print(\"\\nFirst 5 rows (df.head()):\")\n",
        "    print(df.head())\n",
        "\n",
        "    # Display the last few rows\n",
        "    print(\"\\nLast 5 rows (df.tail()):\")\n",
        "    print(df.tail())\n",
        "\n",
        "    # Check unique values in key categorical columns (Occupation type for example)\n",
        "    if 'OCCUPATION_TYPE' in df.columns:\n",
        "        print(\"\\nUnique values in 'OCCUPATION_TYPE':\")\n",
        "        print(df['OCCUPATION_TYPE'].value_counts(dropna=False))\n",
        "\n",
        "    return df\n",
        "\n",
        "# EDA for 'application_record.csv'\n",
        "df1 = pd.read_csv('application_record.csv')\n",
        "df1 = perform_eda(df1, 'application_record')\n",
        "\n",
        "# EDA for 'credit_record.csv'\n",
        "df2 = pd.read_csv('credit_record.csv')\n",
        "df2 = perform_eda(df2, 'credit_record')\n",
        "\n",
        "# Step 2: Merge datasets\n",
        "# if os.path.exists(\"mergedDataset.csv\"):\n",
        "#     print(\"Merged dataset found. Loading it...\")\n",
        "#     final_df = pd.read_csv(\"mergedDataset.csv\")\n",
        "# else:\n",
        "#     print(\"Merging datasets...\")\n",
        "#     final_df = pd.merge(df1, df2, on=\"ID\", how=\"inner\")\n",
        "#     final_df.to_csv(\"mergedDataset.csv\", index=False)\n",
        "\n",
        "print('----------------------------------------------------------------------------\\n');\n",
        "print(\"Number of classes:\", df2[\"STATUS\"].nunique())\n",
        "print(\"Actual classes:\", df2[\"STATUS\"].unique())\n",
        "\n",
        "# Step 5: Map 'STATUS' to binary labels\n",
        "status_mapping = {'C': 0, 'X': 0, '0': 1, '1': 1, '2': 1, '3': 1, '4': 1, '5': 1}\n",
        "df2[\"STATUS\"] = df2[\"STATUS\"].map(status_mapping)\n",
        "\n",
        "print('----------------------------------------------------------------------------\\n');\n",
        "print(\"Number of classes:\", df2[\"STATUS\"].nunique())\n",
        "print(\"Actual classes:\", df2[\"STATUS\"].unique())\n",
        "\n",
        "final_df = pd.merge(df1, df2, on=\"ID\", how=\"inner\")\n",
        "\n",
        "print('----------------------------------------------------------------------------\\n');\n",
        "print(\"Number of classes:\", final_df[\"STATUS\"].nunique())\n",
        "print(\"Actual classes:\", final_df[\"STATUS\"].unique())\n",
        "\n",
        "# Step 3: Encode categorical features\n",
        "labelEncoder = LabelEncoder()\n",
        "dataToEncode = [\n",
        "    \"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\",\n",
        "    \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\",\n",
        "    \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\", \"OCCUPATION_TYPE\"\n",
        "]\n",
        "\n",
        "for label in dataToEncode:\n",
        "    if label in final_df.columns:\n",
        "        final_df[label + \"_Encoded\"] = labelEncoder.fit_transform(final_df[label])\n",
        "    else:\n",
        "        print(f\"Column '{label}' not found in the dataset.\")\n",
        "\n",
        "# Drop original categorical columns after encoding\n",
        "final_df.drop(columns=[col for col in dataToEncode if col in final_df.columns], inplace=True)\n",
        "\n",
        "# Step 4: Move 'STATUS' column to the end\n",
        "if 'STATUS' in final_df.columns:\n",
        "    column_to_move = 'STATUS'\n",
        "    last_column = final_df.pop(column_to_move)\n",
        "    final_df[column_to_move] = last_column\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"******************************************************************\")\n",
        "print(\"FINAL DF IS NAN\",final_df[\"STATUS\"].isna().sum())\n",
        "print(\"FINAL DF IS NULL\",final_df[\"STATUS\"].isnull().sum())\n",
        "print(\"******************************************************************\")\n",
        "\n",
        "\n",
        "# Step 6: Check and clean data\n",
        "# Print initial count of duplicates and missing values\n",
        "print(f\"Initial number of duplicates: {final_df.duplicated().sum()}\")\n",
        "print(f\"Initial number of missing values: {final_df.isnull().sum().sum()}\")\n",
        "\n",
        "# Drop duplicates\n",
        "final_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Fill missing values with -1\n",
        "final_df.fillna(-1, inplace=True)\n",
        "\n",
        "# Print number of duplicates and missing values after cleaning\n",
        "print(f\"After cleaning, number of duplicates: {final_df.duplicated().sum()}\")\n",
        "print(f\"After cleaning, number of missing values: {final_df.isnull().sum().sum()}\")\n",
        "\n",
        "\n",
        "print(\"******************************************************************\")\n",
        "print(\"FINAL DF IS NAN\",final_df[\"STATUS\"].isna().sum())\n",
        "print(\"FINAL DF IS NULL\",final_df[\"STATUS\"].isnull().sum())\n",
        "print(\"******************************************************************\")\n",
        "\n",
        "\n",
        "# Identify garbage values and handle them\n",
        "# Example: If any numeric columns have negative values where they shouldn't, replace them with median or a suitable value\n",
        "for column in final_df.select_dtypes(include=['int64', 'float64']).columns:\n",
        "    # Identify negative values or out-of-range values (example: negative age or income)\n",
        "    if final_df[column].min() < 0:\n",
        "        print(f\"Found negative values in column '{column}'. Replacing with median.\")\n",
        "        median_value = final_df[column][final_df[column] >= 0].median()  # Median of valid values\n",
        "        final_df[column] = final_df[column].apply(lambda x: median_value if x < 0 else x)\n",
        "\n",
        "# Example: Check for unexpected values in categorical columns\n",
        "# Adjust as necessary based on your dataset's requirements\n",
        "categorical_columns = [\n",
        "    \"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\", \"NAME_INCOME_TYPE\",\n",
        "    \"NAME_EDUCATION_TYPE\", \"NAME_FAMILY_STATUS\", \"NAME_HOUSING_TYPE\", \"OCCUPATION_TYPE\"\n",
        "]\n",
        "\n",
        "for col in categorical_columns:\n",
        "    if col in final_df.columns:\n",
        "        unique_values = final_df[col].unique()\n",
        "        print(f\"Unique values in column '{col}': {unique_values}\")\n",
        "        # Check for any unexpected or unwanted values, for example\n",
        "        if col == 'OCCUPATION_TYPE':  # Example: If there are any unknown occupations\n",
        "            invalid_values = final_df[~final_df[col].isin(['high_skill', 'low_skill', 'other'])]  # Adjust categories as needed\n",
        "            print(f\"Found invalid values in '{col}': {invalid_values[col].unique()}\")\n",
        "            final_df[col] = final_df[col].apply(lambda x: 'other' if x not in ['high_skill', 'low_skill', 'other'] else x)\n",
        "\n",
        "# After cleaning, print summary\n",
        "print(f\"After cleaning, number of records: {final_df.shape[0]}\")\n",
        "\n",
        "# Step 7: Save the cleaned dataset back to the same file\n",
        "final_df.to_csv(\"mergedDataset.csv\", index=False)\n",
        "print(\"Cleaned dataset saved to 'mergedDataset.csv'\")\n",
        "\n",
        "# Step 8: Handle missing values and impute missing data using SimpleImputer\n",
        "X = final_df.drop(columns=[\"STATUS\"])\n",
        "y = final_df[\"STATUS\"]\n",
        "\n",
        "y.fillna('1',inplace=True)\n",
        "\n",
        "print(\"***********************************************\\n\" , y.isnull().sum() )\n",
        "print(\"Number of classes:\", y.nunique())\n",
        "print(\"Actual classes:\", y.unique())\n",
        "\n",
        "# Impute missing values in X (features)\n",
        "imputer = SimpleImputer(strategy='mean')  # You can also use 'median' or 'most_frequent'\n",
        "X_imputed = imputer.fit_transform(X)  # Apply imputation to the feature set\n",
        "\n",
        "# Print if there are still missing values\n",
        "print(f\"Missing values after imputation: {pd.isnull(X_imputed).sum()}\")\n",
        "\n",
        "# Step 9: Apply SMOTE to balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_imputed, y)\n",
        "\n",
        "\n",
        "print(X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Split data into Train (70%), Validation (15%), and Test (15%)\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X_resampled, y_resampled, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.1765, random_state=42)\n",
        "\n",
        "\n",
        "originalDfColumns = ['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
        "       'FLAG_MOBIL', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
        "       'CNT_FAM_MEMBERS', 'MONTHS_BALANCE', 'CODE_GENDER_Encoded',\n",
        "       'FLAG_OWN_CAR_Encoded', 'FLAG_OWN_REALTY_Encoded',\n",
        "       'NAME_INCOME_TYPE_Encoded', 'NAME_EDUCATION_TYPE_Encoded',\n",
        "       'NAME_FAMILY_STATUS_Encoded', 'NAME_HOUSING_TYPE_Encoded',\n",
        "       'OCCUPATION_TYPE_Encoded']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Scale numerical data\n",
        "scaler = StandardScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=originalDfColumns)\n",
        "X_val = pd.DataFrame(scaler.transform(X_val), columns=originalDfColumns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=originalDfColumns)\n",
        "\n",
        "# Step 11: Genetic Algorithm for Feature Selection\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_bool\", np.random.randint, 0, 2)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X_train.columns))\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "def evaluate(individual):\n",
        "    selected_features = [feature for feature, select in zip(X_train.columns, individual) if select == 1]\n",
        "    if len(selected_features) == 0:\n",
        "        return 0,\n",
        "    clf = DecisionTreeClassifier(random_state=42)\n",
        "    clf.fit(X_train[selected_features], y_train)\n",
        "    y_val_pred = clf.predict(X_val[selected_features])\n",
        "    return accuracy_score(y_val, y_val_pred),  # Fitness is validation accuracy\n",
        "\n",
        "toolbox.register(\"evaluate\", evaluate)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.1)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "# Step 12: Optimize with Genetic Algorithm\n",
        "population = toolbox.population(n=20)\n",
        "ngen, cxpb, mutpb = 10, 0.7, 0.3\n",
        "result = algorithms.eaSimple(population, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=ngen, verbose=True)\n",
        "\n",
        "# Step 13: Extract the best features\n",
        "best_individual = tools.selBest(population, k=1)[0]\n",
        "selected_features = [feature for feature, select in zip(X_train.columns, best_individual) if select == 1]\n",
        "print(\"\\nSelected Features:\", selected_features)\n",
        "\n",
        "# Step 14: Hyperparameter Tuning with RandomizedSearchCV\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdssYh5nnVPT",
        "outputId": "3491f4bc-7dc3-486f-fafa-ad3c188570a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.10/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gen\tnevals\n",
            "0  \t20    \n",
            "1  \t15    \n",
            "2  \t17    \n",
            "3  \t16    \n",
            "4  \t19    \n",
            "5  \t13    \n",
            "6  \t15    \n",
            "7  \t16    \n",
            "8  \t15    \n",
            "9  \t15    \n",
            "10 \t14    \n",
            "\n",
            "Selected Features: ['CNT_CHILDREN', 'DAYS_BIRTH', 'FLAG_WORK_PHONE', 'FLAG_EMAIL', 'CNT_FAM_MEMBERS', 'FLAG_OWN_REALTY_Encoded', 'NAME_INCOME_TYPE_Encoded', 'NAME_EDUCATION_TYPE_Encoded', 'NAME_HOUSING_TYPE_Encoded', 'OCCUPATION_TYPE_Encoded']\n",
            "\n",
            "Tuning hyperparameters for KNN...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Random Search Best Parameters: {'weights': 'distance', 'n_neighbors': 4, 'metric': 'euclidean'}\n",
            "KNN Random Search Best Score: 0.75\n",
            "\n",
            "KNN Test Accuracy with Best Model: 0.75\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.85      0.77     71147\n",
            "           1       0.81      0.65      0.72     71499\n",
            "\n",
            "    accuracy                           0.75    142646\n",
            "   macro avg       0.76      0.75      0.75    142646\n",
            "weighted avg       0.76      0.75      0.75    142646\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_dist_dt = {\n",
        "    \"max_depth\": [3, 5, 10, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "param_dist_knn = {\n",
        "    \"n_neighbors\": [3,4,5,9],\n",
        "    \"weights\": [\"uniform\", \"distance\"],\n",
        "    \"metric\": [\"euclidean\", \"manhattan\"]\n",
        "}\n",
        "\n",
        "param_dist_mlp = {\n",
        "    \"hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
        "    \"activation\": [\"relu\", \"tanh\"],\n",
        "    \"solver\": [\"adam\", \"sgd\"],\n",
        "    \"learning_rate\": [\"constant\", \"adaptive\"]\n",
        "}\n",
        "\n",
        "models = {\n",
        "    \"KNN\": (KNeighborsClassifier(), param_dist_knn),\n",
        "    \"DecisionTree\": (DecisionTreeClassifier(random_state=42), param_dist_dt),\n",
        "    \"MLP\": (MLPClassifier(random_state=42, max_iter=300), param_dist_mlp)\n",
        "}\n",
        "\n",
        "for model_name, (model, param_dist) in models.items():\n",
        "    print(f\"\\nTuning hyperparameters for {model_name}...\")\n",
        "\n",
        "    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=10, cv=3, random_state=42, scoring=\"accuracy\", n_jobs=-1)\n",
        "    random_search.fit(X_train[selected_features], y_train)\n",
        "\n",
        "    print(f\"{model_name} Random Search Best Parameters: {random_search.best_params_}\")\n",
        "    print(f\"{model_name} Random Search Best Score: {random_search.best_score_:.2f}\")\n",
        "\n",
        "    # Evaluate on test set using the best RandomizedSearchCV model\n",
        "    best_model = random_search.best_estimator_\n",
        "    y_test_pred = best_model.predict(X_test[selected_features])\n",
        "    print(f\"\\n{model_name} Test Accuracy with Best Model: {accuracy_score(y_test, y_test_pred):.2f}\")\n",
        "    print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "OJAh23U71Fl2",
        "outputId": "b5fe288d-d2bb-4f3e-efe2-92abe4e8e4e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tuning hyperparameters for KNN...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d47669f3a536>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{model_name} Random Search Best Parameters: {random_search.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1950\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1951\u001b[0m             ParameterSampler(\n\u001b[1;32m   1952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    967\u001b[0m                     )\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    970\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    971\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}